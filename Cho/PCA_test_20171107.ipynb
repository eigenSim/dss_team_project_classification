{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, log_loss\n",
    "\n",
    "######################################  Image contol  ######################################\n",
    "\n",
    "import cv2\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "######################################       PCA      ######################################\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encogin categorical values for further processing\n",
    "def encode_cat(df):\n",
    "    \"\"\"\n",
    "       Input : train_df \n",
    "       Output : encoded_train_df\n",
    "    \"\"\"\n",
    "    # get categorical(type='object') variable\n",
    "    cat_var_df = df.select_dtypes(include=['object']).copy()    \n",
    "    \n",
    "    cleanup_nums = {}\n",
    "    \n",
    "    # species columns encoding\n",
    "    spe_index = 0\n",
    "    spe_enc_dict = {}\n",
    "    for key in set(cat_var_df['species'].values):\n",
    "        spe_enc_dict[key] = spe_index\n",
    "        spe_index += 1\n",
    "    cleanup_nums['species'] = spe_enc_dict\n",
    "    \n",
    "    try:\n",
    "        cat_var_df.replace(cleanup_nums, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df = df.drop(cat_var_df.columns, axis=1)\n",
    "    df = pd.concat([df, cat_var_df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../train.csv\")\n",
    "test_df = pd.read_csv(\"../test.csv\")\n",
    "\n",
    "# encoded('species') version of train_df\n",
    "train_df_enc = encode_cat(train_df)\n",
    "dfX = train_df_enc.drop(['id', 'species'], axis=1)\n",
    "dfy = train_df_enc.loc[:, 'species']\n",
    "\n",
    "# dfX scaled, standardized\n",
    "dfX_minmax_scaled = pd.DataFrame(MinMaxScaler().fit_transform(dfX), columns=dfX.columns)\n",
    "dfX_std_scaled = pd.DataFrame(StandardScaler().fit_transform(dfX), columns=dfX.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source : https://datascienceschool.net/view-notebook/f10aad8a34a4489697933f77c5d58e3a/\n",
    "pca = PCA().fit(dfX_std_scaled)\n",
    "var = pca.explained_variance_\n",
    "cmap = sns.color_palette()\n",
    "plt.bar(np.arange(1,len(var)+1), var/np.sum(var), align=\"center\", color=cmap[0])\n",
    "plt.step(np.arange(1,len(var)+1), np.cumsum(var)/np.sum(var), where=\"mid\", color=cmap[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = sns.color_palette()\n",
    "plt.bar(np.arange(1,len(var)+1), var/np.sum(var), align=\"center\", color=cmap[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=40).fit(dfX_std_scaled)\n",
    "Z_df = pd.DataFrame(pca1.transform(dfX_std_scaled), columns=range(40))\n",
    "Z_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfX_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = pca.transform(dfX)\n",
    "Z.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
